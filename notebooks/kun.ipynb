{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-04 23:10:52.820897: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tensorflow.keras import layers, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 67467 entries, 0 to 67466\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   tweet        67467 non-null  object\n",
      " 1   y            67467 non-null  bool  \n",
      " 2   tweet_clean  67120 non-null  object\n",
      "dtypes: bool(1), object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data_path = '/Users/kun/code/kun1887/TwitPol/data_cleaned.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28220    mean go build bomb go cut health care kid say ...\n",
       "38702    democratic republican leader senate hold gover...\n",
       "39878        ann train fine pray comfort family individual\n",
       "7108     dr james west make black history day creator w...\n",
       "6604     thank attend recent passport fair unable atten...\n",
       "6778      livestream question facebook ceo mark zuckerberg\n",
       "52103    .#taxcuts lead high wage pay parental leave \\n...\n",
       "29272    look forward take live discussion morning achi...\n",
       "30799    live soon floor talk h.con.re encourage reunio...\n",
       "14915                             president trump try hide\n",
       "Name: tweet_clean, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)['tweet_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.tweet_clean\n",
    "y = data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "for x in '1 2 3.':\n",
    "    print(type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_string = \"Hello, World!\"\n",
    "type(my_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m Tokenizer()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_on_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m X_train_tok \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mtexts_to_sequences(X_train)\n\u001b[1;32m      4\u001b[0m X_test_tok \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mtexts_to_sequences(X_test)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/twitpol/lib/python3.10/site-packages/keras/src/legacy/preprocessing/text.py:133\u001b[0m, in \u001b[0;36mTokenizer.fit_on_texts\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manalyzer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 133\u001b[0m         seq \u001b[38;5;241m=\u001b[39m \u001b[43mtext_to_word_sequence\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m            \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m         seq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manalyzer(text)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/twitpol/lib/python3.10/site-packages/keras/src/legacy/preprocessing/text.py:22\u001b[0m, in \u001b[0;36mtext_to_word_sequence\u001b[0;34m(input_text, filters, lower, split)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"DEPRECATED.\"\"\"\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lower:\n\u001b[0;32m---> 22\u001b[0m     input_text \u001b[38;5;241m=\u001b[39m \u001b[43minput_text\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m()\n\u001b[1;32m     24\u001b[0m translate_dict \u001b[38;5;241m=\u001b[39m {c: split \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m filters}\n\u001b[1;32m     25\u001b[0m translate_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m\u001b[38;5;241m.\u001b[39mmaketrans(translate_dict)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_tok = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_tok = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.average([len(x) for x in X_train_tok])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocal_size = len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pad = pad_sequences(X_train_tok, dtype='int', padding='post', maxlen=10)\n",
    "X_test_pad = pad_sequences(X_test_tok, dtype='int', padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_pad.shape)\n",
    "print(X_test_pad.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pad[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(layers.Embedding(input_dim=vocal_size + 1, output_dim=50))\n",
    "    model.add(layers.LSTM(5))\n",
    "    model.add(layers.Dense(12, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_model()\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_pad,\n",
    "    y_train,\n",
    "    epochs=5,\n",
    "    validation_split=0.3,\n",
    "    batch_size=128,\n",
    "    verbose=2\n",
    "    )\n",
    "\n",
    "plot_loss_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_accuracy(history, title=None):\n",
    "    fig, ax = plt.subplots(1,2, figsize=(20,7))\n",
    "\n",
    "    # --- LOSS ---\n",
    "\n",
    "    ax[0].plot(history.history['loss'])\n",
    "    ax[0].plot(history.history['val_loss'])\n",
    "\n",
    "    ax[0].set_title('Model loss')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "\n",
    "    ax[0].set_ylim((0,1))\n",
    "\n",
    "    ax[0].legend(['Train', 'Test'], loc='best')\n",
    "\n",
    "    ax[0].grid(axis=\"x\",linewidth=0.5)\n",
    "    ax[0].grid(axis=\"y\",linewidth=0.5)\n",
    "\n",
    "    # --- ACCURACY\n",
    "\n",
    "    ax[1].plot(history.history['accuracy'])\n",
    "    ax[1].plot(history.history['val_accuracy'])\n",
    "\n",
    "    ax[1].set_title('Model Accuracy')\n",
    "    ax[1].set_ylabel('Accuracy')\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "\n",
    "    ax[1].legend(['Train', 'Test'], loc='best')\n",
    "\n",
    "    ax[1].set_ylim((0,1))\n",
    "\n",
    "    ax[1].grid(axis=\"x\",linewidth=0.5)\n",
    "    ax[1].grid(axis=\"y\",linewidth=0.5)\n",
    "\n",
    "    if title:\n",
    "        fig.suptitle(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = model.layers[0].weights[0]._value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = [\"I vote for Trump\"]\n",
    "\n",
    "tokenized = tokenizer.texts_to_sequences(example)\n",
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = pad_sequences(tokenized, dtype='int', padding='post', maxlen=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "class KerasClassifierWrapper:\n",
    "    def __init__(self, model, tokenizer, maxlen):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.maxlen = maxlen\n",
    "\n",
    "    def predict_proba(self, texts):\n",
    "        sequences = self.tokenizer.texts_to_sequences(texts)\n",
    "        padded = pad_sequences(sequences, maxlen=self.maxlen, padding='post')\n",
    "        return np.hstack((1 - self.model.predict(padded), self.model.predict(padded)))\n",
    "\n",
    "wrapper = KerasClassifierWrapper(model, tokenizer, X_train_pad.shape[1])\n",
    "ls_X_test = cleaned_texts  # Your test data should be prepared similarly\n",
    "class_names = {0: 'non-democratic', 1: 'democratic'}\n",
    "\n",
    "explainer = LimeTextExplainer(class_names=class_names)\n",
    "\n",
    "idx = np.random.randint(200)\n",
    "explanation = explainer.explain_instance(ls_X_test[idx], wrapper.predict_proba, num_features=6)\n",
    "print('Document id: %d' % idx)\n",
    "print('Text: ', ls_X_test[idx])\n",
    "print('Probability democratic =', wrapper.predict_proba([ls_X_test[idx]]).round(3)[0,1])\n",
    "print('True class: %s' % class_names[data.iloc[idx]['y']])\n",
    "\n",
    "# Show the explainability results with highlighted text\n",
    "print(\"1 = democratuc class, 0 = non-democratic class\")\n",
    "explanation.show_in_notebook(text=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
