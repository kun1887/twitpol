{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tensorflow.keras import layers, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/kun/code/kun1887/TwitPol/data_cleaned.csv'\n",
    "data = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "False    34452\n",
       "True     33015\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y.astype(bool).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.tweet_clean\n",
    "y = data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34473    good news dickinson county base company specia...\n",
       "13316                  year wait guy bring job talk action\n",
       "63261    congratulation name th president louisville se...\n",
       "20217    tax cut pay republican want pay goptaxscam cut...\n",
       "8304     release classified information nunesmemo egreg...\n",
       "                               ...                        \n",
       "37194    honor understatement humble thank vietnam vete...\n",
       "6265         like offer special thank amp leadership issue\n",
       "54886    colleague urge ambassador lighthizer maintain ...\n",
       "860      want thank city council staff leadership commu...\n",
       "15795    today send letter facebook founder ceo mark zu...\n",
       "Name: tweet_clean, Length: 60720, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m Tokenizer()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_on_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m X_train_tok \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mtexts_to_sequences(X_train)\n\u001b[1;32m      4\u001b[0m X_test_tok \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mtexts_to_sequences(X_test)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/twitpol/lib/python3.10/site-packages/keras/src/legacy/preprocessing/text.py:133\u001b[0m, in \u001b[0;36mTokenizer.fit_on_texts\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manalyzer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 133\u001b[0m         seq \u001b[38;5;241m=\u001b[39m \u001b[43mtext_to_word_sequence\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m            \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m         seq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manalyzer(text)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/twitpol/lib/python3.10/site-packages/keras/src/legacy/preprocessing/text.py:22\u001b[0m, in \u001b[0;36mtext_to_word_sequence\u001b[0;34m(input_text, filters, lower, split)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"DEPRECATED.\"\"\"\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lower:\n\u001b[0;32m---> 22\u001b[0m     input_text \u001b[38;5;241m=\u001b[39m \u001b[43minput_text\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m()\n\u001b[1;32m     24\u001b[0m translate_dict \u001b[38;5;241m=\u001b[39m {c: split \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m filters}\n\u001b[1;32m     25\u001b[0m translate_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m\u001b[38;5;241m.\u001b[39mmaketrans(translate_dict)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_tok = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_tok = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.average([len(x) for x in X_train_tok])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocal_size = len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pad = pad_sequences(X_train_tok, dtype='int', padding='post', maxlen=10)\n",
    "X_test_pad = pad_sequences(X_test_tok, dtype='int', padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_pad.shape)\n",
    "print(X_test_pad.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pad[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(layers.Embedding(input_dim=vocal_size + 1, output_dim=50))\n",
    "    model.add(layers.LSTM(5))\n",
    "    model.add(layers.Dense(12, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_model()\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_pad,\n",
    "    y_train == \"True\",\n",
    "    epochs=5,\n",
    "    validation_split=0.3,\n",
    "    batch_size=128,\n",
    "    verbose=2\n",
    "    )\n",
    "\n",
    "plot_loss_accuracy(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_accuracy(history, title=None):\n",
    "    fig, ax = plt.subplots(1,2, figsize=(20,7))\n",
    "\n",
    "    # --- LOSS ---\n",
    "\n",
    "    ax[0].plot(history.history['loss'])\n",
    "    ax[0].plot(history.history['val_loss'])\n",
    "\n",
    "    ax[0].set_title('Model loss')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "\n",
    "    ax[0].set_ylim((0,1))\n",
    "\n",
    "    ax[0].legend(['Train', 'Test'], loc='best')\n",
    "\n",
    "    ax[0].grid(axis=\"x\",linewidth=0.5)\n",
    "    ax[0].grid(axis=\"y\",linewidth=0.5)\n",
    "\n",
    "    # --- ACCURACY\n",
    "\n",
    "    ax[1].plot(history.history['accuracy'])\n",
    "    ax[1].plot(history.history['val_accuracy'])\n",
    "\n",
    "    ax[1].set_title('Model Accuracy')\n",
    "    ax[1].set_ylabel('Accuracy')\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "\n",
    "    ax[1].legend(['Train', 'Test'], loc='best')\n",
    "\n",
    "    ax[1].set_ylim((0,1))\n",
    "\n",
    "    ax[1].grid(axis=\"x\",linewidth=0.5)\n",
    "    ax[1].grid(axis=\"y\",linewidth=0.5)\n",
    "\n",
    "    if title:\n",
    "        fig.suptitle(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = model.layers[0].weights[0]._value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = [\"I vote for Trump\"]\n",
    "\n",
    "tokenized = tokenizer.texts_to_sequences(example)\n",
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = pad_sequences(tokenized, dtype='int', padding='post', maxlen=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "class KerasClassifierWrapper:\n",
    "    def __init__(self, model, tokenizer, maxlen):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.maxlen = maxlen\n",
    "\n",
    "    def predict_proba(self, texts):\n",
    "        sequences = self.tokenizer.texts_to_sequences(texts)\n",
    "        padded = pad_sequences(sequences, maxlen=self.maxlen, padding='post')\n",
    "        return np.hstack((1 - self.model.predict(padded), self.model.predict(padded)))\n",
    "\n",
    "wrapper = KerasCtweet = data.tweet_clean[0]lassifierWrapper(model, tokenizer, X_train_pad.shape[1])\n",
    "ls_X_test = cleaned_texts  # Your test data should be prepared similarly\n",
    "class_names = {0: 'non-democratic', 1: 'democratic'}\n",
    "\n",
    "explainer = LimeTextExplainer(class_names=class_names)\n",
    "\n",
    "idx = np.random.randint(200)\n",
    "explanation = explainer.explain_instance(ls_X_test[idx], wrapper.predict_proba, num_features=6)\n",
    "print('Document id: %d' % idx)\n",
    "print('Text: ', ls_X_test[idx])\n",
    "print('Probability democratic =', wrapper.predict_proba([ls_X_test[idx]]).round(3)[0,1])\n",
    "print('True class: %s' % class_names[data.iloc[idx]['y']])\n",
    "\n",
    "# Show the explainability results with highlighted text\n",
    "print(\"1 = democratuc class, 0 = non-democratic class\")\n",
    "explanation.show_in_notebook(text=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = data.tweet_clean[33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'let face planet b'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os \n",
    "# Set your OpenAI API key\n",
    "api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "query = f\"Classify this tweet as Democratic or Republican: {tweet}\"\n",
    "response = client.chat.completions.create(model='gpt-3.5-turbo', messages=[\n",
    "    {'role':'system', 'content': 'You are a tweet classifier for political sentiment. Be brief and concise.'},\n",
    "    {'role':'user', 'content':query}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
